\section{Results}

\subsection{Training comparison}

The training phase of a Reinforcement Learning agent and a Genetic Algorithm are fundamentally different.
Therefore, we had to find a way to harmonize the training data of the two methods in order to compare them.
\\
Our first idea was to consider RL episodes the same as GA individuals and aggregate the RL performances to match the number of generations used for GA.
For example if we had a population size of $k$ for our Genetic Algorithm, we would take the max and mean of every last $k$ Reinforcement Learning episodes to compare them with each GA generation.
\\
Due to the inherent difference between GA which performs a form of parallel search and RL which iteratively improves each episode, we decided to not alter the training data at all and take a more empirical approach.
The comparison we ended up using is thus simply tracking the training time (in seconds) and plotting the performances achieved over time. (Of course both algorithms need to be ran on the same machine for a fair comparison).
\\
Let us take a look at both average and best results achieved over training time for our two methods.

\begin{figure}[H]
	\centering
	\includegraphics [scale = 0.5]{Images/RL_GA_comparison_avg.png}
	\caption{placeholer}
	\label{figAVG}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics [scale = 0.5]{Images/RL_GA_comparison_max.png}
	\caption{placeholer}
	\label{figMAX}
\end{figure}



\subsection{final model comparison}

\begin{figure}[H]
	\centering
	\includegraphics [scale = 0.7]{Images/diff.png}
	\caption{Difference between the two state action tables obtained using GA and RL. The black pixels represents the states where choosen action is the same, white pixels represent a different action's choice. The x-axis contains all the possible pairs of the first two elements of the state's 4D-vector, $(s_1,s_2)$, y-axis all the possible pairs of the last two elements $(s_3,s_4)$. }
	\label{figTABLEDIFF}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics [width=0.5\textwidth]{Images/GAvRL_backup.png}
	\caption{The plot shows the results obtained testing the two models on the same test set. The x-axis represents the number of the test set, the y-axis the number of steps the model was able to take before reaching the goal. The blue line represents the results obtained using the model trained with the GA, the red line the results obtained using the model trained with the RL.}
	\label{figRLvsGA}
\end{figure}
% % Delete the text and write your Results here:
% %------------------------------------

% The results section can be combined with the discussion if appropriate. In case of many sub\-/experiments % \-/ fixes the problem that LaTeX won't hyphenate words with dashes in them.
% where the results are vaguely related or unrelated, it would be appropriate to combine the results and discussion. This way you have the information related to each sub-experiment gathered in one place. \par
% Provide uncertainties for the results, but don't discuss it. Do not involve personal opinions, just present the cold hard results in form of numbers, tables, graphs and some sentences. \par
% \Cref{tab:Some-numbers} shows a nice table with comma alignment. \par

% \begin{table}[htb]%
% \centering
% \caption{Table with comma alignment.}
% 	\label{tab:Some-numbers}
% 	\begin{tabular}{SSS} 		% S = special column format from the siunitx package. Aligns commas.
% 		\toprule
% 		{$m$}  &  {$a$}  & {$F$}  \\
% 		{(\si{kg})} &  {(\si{m.s^{-2}})} & {(\si{N})}  \\
% 		\midrule
% 		1,2 & 10,1 & 12 \\
% 		2,44 & 6,92 & 16,88 \\
% 		10 & 1,0 & 10 \\
% 		8,2 & 1,1 & 9,0 \\
% 		100 & 1 & 100 \\
% 		\bottomrule
% 	\end{tabular}
% \end{table}

